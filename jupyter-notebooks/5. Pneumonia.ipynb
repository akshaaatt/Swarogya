{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhSdg-ajWs4l",
    "outputId": "d4d1c231-1a16-4da1-f8f0-6ae0504a7846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading chest-xray-pneumonia.zip to /content\n",
      "100% 2.29G/2.29G [00:30<00:00, 27.1MB/s]\n",
      "100% 2.29G/2.29G [00:30<00:00, 81.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \"\" # key from the json file\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dC9uJkrcXPb7"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/chest-xray-pneumonia\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-82iQLgPW2Rx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten, Dense,MaxPool2D, Dropout\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pROTcEkMYzxG"
   },
   "outputs": [],
   "source": [
    "train_dir = \"chest_xray/train\"\n",
    "test_dir = \"chest_xray/test\"\n",
    "val_dir = \"chest_xray/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tJxPdOSHZgTc"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6M5EoCzfZi1X",
    "outputId": "f8b0a71b-d165-47ef-be10-961a94828733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications import VGG16\n",
    "\n",
    "vgg_model = VGG16(input_shape= (IMG_SIZE, IMG_SIZE,3), \n",
    "                  weights='imagenet',\n",
    "                  include_top=False)\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r_LywuDVZmNZ"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "vgg_output = vgg_model.output\n",
    "\n",
    "flatten = Flatten()(vgg_output)\n",
    "Dense_layer1 = Dense(units = 256,activation='relu')(flatten)\n",
    "Dense_layer2 = Dense(units=128,activation='relu')(Dense_layer1)\n",
    "Dense_layer3 = Dense(units = 64,activation='relu')(Dense_layer2)\n",
    "output_layer = Dense(2,activation='sigmoid')(Dense_layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gCGWhnm1Zp8q"
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "\n",
    "model = Model(inputs = vgg_model.input, outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rjy-G0SeZt7c"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pR8eAAI3Z4iJ",
    "outputId": "49b644d0-6d01-4dd3-9ca2-5061efcf7ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "100/100 [==============================] - 108s 702ms/step - loss: 0.3533 - accuracy: 0.8279 - val_loss: 0.2723 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89744, saving model to vgg16_model_file.h5\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 67s 671ms/step - loss: 0.1285 - accuracy: 0.9476 - val_loss: 0.2820 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.89744\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 0.1468 - accuracy: 0.9350 - val_loss: 0.5049 - val_accuracy: 0.8157\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.89744\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.1667 - accuracy: 0.9307 - val_loss: 0.2563 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.89744 to 0.91026, saving model to vgg16_model_file.h5\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.1160 - accuracy: 0.9499 - val_loss: 0.2363 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91026 to 0.92308, saving model to vgg16_model_file.h5\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 68s 676ms/step - loss: 0.1008 - accuracy: 0.9545 - val_loss: 0.3877 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.92308\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 67s 669ms/step - loss: 0.0841 - accuracy: 0.9688 - val_loss: 0.2474 - val_accuracy: 0.9071\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.92308\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 67s 671ms/step - loss: 0.1252 - accuracy: 0.9513 - val_loss: 0.3915 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.92308\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 67s 670ms/step - loss: 0.0765 - accuracy: 0.9709 - val_loss: 0.2848 - val_accuracy: 0.9022\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.92308\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 67s 670ms/step - loss: 0.0870 - accuracy: 0.9658 - val_loss: 0.3725 - val_accuracy: 0.8846\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.92308\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.0988 - accuracy: 0.9597 - val_loss: 0.2787 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.92308\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 67s 671ms/step - loss: 0.0789 - accuracy: 0.9722 - val_loss: 0.2693 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92308\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 67s 665ms/step - loss: 0.1027 - accuracy: 0.9625 - val_loss: 0.2523 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92308\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 66s 665ms/step - loss: 0.0684 - accuracy: 0.9717 - val_loss: 0.4443 - val_accuracy: 0.8782\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.92308\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 67s 667ms/step - loss: 0.0987 - accuracy: 0.9604 - val_loss: 0.3980 - val_accuracy: 0.8846\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.92308\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_generator_train = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = False\n",
    ")\n",
    "\n",
    "\n",
    "image_generator_test = ImageDataGenerator(\n",
    "     rescale = 1./255\n",
    "\n",
    ")\n",
    "\n",
    "train = image_generator_train.flow_from_directory(train_dir, \n",
    "                                            batch_size=32,\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size = (IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "validation = image_generator_test.flow_from_directory(test_dir, \n",
    "                                                batch_size=32,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode='categorical',\n",
    "                                                target_size = (IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "callback_list = ModelCheckpoint('vgg16_model_file.h5', \n",
    "                                 monitor='val_accuracy', \n",
    "                                 verbose=True, \n",
    "                                 save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train,\n",
    "    epochs = 15,\n",
    "    validation_data = validation,\n",
    "    validation_steps = len(validation),\n",
    "    steps_per_epoch = 100,\n",
    "    callbacks = [callback_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fx9wFKvNaSDk",
    "outputId": "35d923b7-7b28-494f-f6f5-194600281988"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "img = image.load_img('/content/chest_xray/test/PNEUMONIA/person100_bacteria_475.jpeg', target_size = (img_width, img_height))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "np.argmax(model.predict(img), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nPAY_BG8Zwm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "7_Pneumonia.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
